{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d0b4a-3e92-49ce-a40e-6e5352f39114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U torch sahi ultralytics\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d1215-ee94-4438-9aa7-3f4a9e817dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi import AutoDetectionModel\n",
    "from sahi.utils.cv import read_image\n",
    "from sahi.utils.file import download_from_url\n",
    "from sahi.predict import get_prediction, get_sliced_prediction, predict\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35982f-f5af-4d50-9037-67fb52a86bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "image = Image.open(\"/home/dhfmd/Dinglun/0529_small_RGB_V2_V3.tif\")\n",
    "print(image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92185fd-7b46-4c2b-9315-a83437544126",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type='ultralytics',\n",
    "    model_path=\"/home/dhfmd/Dinglun/yolov9/runs/detect/corn30_combine_freeze_0_lr_0.01_batch_16_wd_0.001_dropout_0/weights/best.pt\", # any yolov8/yolov9/yolo11/yolo12/rt-detr det model is supported\n",
    "    confidence_threshold=0.35,\n",
    "    device=\"cuda:0\", # or 'cuda:0' if GPU is available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424e586-5ad4-4564-a5ce-683a73dc2c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = get_sliced_prediction(\n",
    "#     image=image,\n",
    "#     detection_model=detection_model,\n",
    "#     slice_height=512,\n",
    "#     slice_width=512,\n",
    "#     overlap_height_ratio=0.2,\n",
    "#     overlap_width_ratio=0.2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710af25-97d6-4065-9750-1a3501ecd5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.export_visuals(export_dir=\"demo_data/\", hide_conf=True)\n",
    "\n",
    "# image_vis = Image.open(\"demo_data/prediction_visual.png\")\n",
    "# display(image_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c7a897-1ee2-4b26-b28f-66632f8d11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open(\"demo_data/prediction_visual.png\")\n",
    "# print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c344d-e229-482b-9f1c-c504a15cb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropped = img.crop((0, 0, 10240, 10240))  # Upper left corner 1024×1024 area\n",
    "# cropped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b99a627-b0a8-4deb-a905-393e89adea10",
   "metadata": {},
   "source": [
    "### get_prediction per slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ca56f-6c95-4da6-aa9e-0d71c0eef6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "import pandas as pd\n",
    "from sahi.utils.file import save_json\n",
    "from sahi.utils.cv import read_image\n",
    "from sahi.predict import get_prediction\n",
    "from PIL import Image\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def pixel2coord(x, y, geotransform):\n",
    "    xoff, a, b, yoff, d, e = geotransform\n",
    "    xp = a * x + b * y + a * 0.5 + b * 0.5 + xoff\n",
    "    yp = d * x + e * y + d * 0.5 + e * 0.5 + yoff\n",
    "    return xp, yp\n",
    "\n",
    "\n",
    "def slice_image_pil(image: Image.Image, slice_height: int, slice_width: int,\n",
    "                    overlap_height_ratio=0.2, overlap_width_ratio=0.2, return_coordinates=False):\n",
    "    image_width, image_height = image.size\n",
    "    stride_h = int(slice_height * (1 - overlap_height_ratio))\n",
    "    stride_w = int(slice_width * (1 - overlap_width_ratio))\n",
    "\n",
    "    slices = []\n",
    "    coords = []\n",
    "    for top in range(0, image_height, stride_h):\n",
    "        for left in range(0, image_width, stride_w):\n",
    "            bottom = min(top + slice_height, image_height)\n",
    "            right = min(left + slice_width, image_width)\n",
    "            box = (left, top, right, bottom)\n",
    "            cropped_image = image.crop(box)\n",
    "            slices.append(cropped_image)\n",
    "            coords.append(box)\n",
    "    return (slices, coords) if return_coordinates else slices\n",
    "\n",
    "\n",
    "def predict_and_save_each_slice(\n",
    "    tif_path,\n",
    "    model,\n",
    "    output_dir,\n",
    "    slice_height=512,\n",
    "    slice_width=512,\n",
    "    overlap_height_ratio=0.2,\n",
    "    overlap_width_ratio=0.2,\n",
    "    confidence_threshold=0.3\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_csv_dir = os.path.join(output_dir, \"csv\")\n",
    "    output_img_dir = os.path.join(output_dir, \"slices\")\n",
    "    os.makedirs(output_csv_dir, exist_ok=True)\n",
    "    os.makedirs(output_img_dir, exist_ok=True)\n",
    "\n",
    "    # Read image and geo-info\n",
    "    raster = gdal.Open(tif_path)\n",
    "    geotransform = raster.GetGeoTransform()\n",
    "    image = Image.open(tif_path)\n",
    "\n",
    "    # Slice\n",
    "    slice_image_list, box_list = slice_image_pil(\n",
    "        image=image,\n",
    "        slice_height=slice_height,\n",
    "        slice_width=slice_width,\n",
    "        overlap_height_ratio=overlap_height_ratio,\n",
    "        overlap_width_ratio=overlap_width_ratio,\n",
    "        return_coordinates=True,\n",
    "    )\n",
    "\n",
    "    # Predict each slice\n",
    "    for i, (slice_img, box) in enumerate(zip(slice_image_list, box_list)):\n",
    "        left, top, right, bottom = box\n",
    "\n",
    "        result = get_prediction(slice_img, model, shift_amount=[left, top])\n",
    "\n",
    "        records = []\n",
    "        for pred in result.object_prediction_list:\n",
    "            bbox = pred.bbox\n",
    "            xmin = bbox.minx\n",
    "            ymin = bbox.miny\n",
    "            xmax = bbox.maxx\n",
    "            ymax = bbox.maxy\n",
    "            conf = pred.score.value\n",
    "\n",
    "            center_x = (xmin + xmax) / 2\n",
    "            center_y = (ymin + ymax) / 2\n",
    "\n",
    "            # Convert center to global pixel coordinates\n",
    "            global_center_x = center_x + left\n",
    "            global_center_y = center_y + top\n",
    "\n",
    "            # Convert to geographic coordinates\n",
    "            geo_x, geo_y = pixel2coord(global_center_x, global_center_y, geotransform)\n",
    "\n",
    "            records.append({\n",
    "                'xmin': xmin, 'ymin': ymin,\n",
    "                'xmax': xmax, 'ymax': ymax,\n",
    "                'center_x': center_x, 'center_y': center_y,\n",
    "                'global_center_x': global_center_x, 'global_center_y': global_center_y,\n",
    "                'confidence': conf,\n",
    "                'geo_x': geo_x, 'geo_y': geo_y,\n",
    "                'slice_index': i\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(records)\n",
    "        csv_name = f\"slice_{i}.csv\"\n",
    "        df.to_csv(os.path.join(output_csv_dir, csv_name), index=False)\n",
    "\n",
    "        # Save slice image with boxes (optional visualization)\n",
    "        vis_img = np.array(slice_img)[:, :, ::-1].copy()  # PIL -> BGR\n",
    "        for pred in result.object_prediction_list:\n",
    "            box = pred.bbox.to_voc_bbox()\n",
    "            cv2.rectangle(vis_img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 1)\n",
    "        cv2.imwrite(os.path.join(output_img_dir, f\"slice_{i}.png\"), vis_img)\n",
    "\n",
    "        print(f\"[✓] Saved: slice_{i}.csv and slice_{i}.png\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334cf47-abb7-4969-8009-9406e184628e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict_and_save_each_slice(\n",
    "#     tif_path=\"/home/dhfmd/Dinglun/0529_small_RGB_V2_V3.tif\",\n",
    "#     model=detection_model,\n",
    "#     output_dir=\"my_sahi_results\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfd845d-0586-4e06-9102-d834e0b50502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# pixel_dir = \"/home/dhfmd/Dinglun/my_sahi_results/csv\"\n",
    "# combined_csv = \"/home/dhfmd/Dinglun/my_sahi_results/final_combined_geo_pixel.csv\"\n",
    "\n",
    "# all_slice_csvs = glob.glob(os.path.join(pixel_dir, \"slice_*.csv\"))\n",
    "\n",
    "# df_all = []\n",
    "# for csv_file in all_slice_csvs:\n",
    "#     if os.path.getsize(csv_file) == 0:\n",
    "#         continue\n",
    "#     try:\n",
    "#         df = pd.read_csv(csv_file)\n",
    "#         df[\"slice_name\"] = os.path.basename(csv_file).replace(\".csv\", \"\")\n",
    "#         df_all.append(df)\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Error reading {csv_file}: {e}\")\n",
    "\n",
    "# # Merge and save\n",
    "# combined_df = pd.concat(df_all, ignore_index=True)\n",
    "# combined_df.to_csv(combined_csv, index=False)\n",
    "# print(f\"✅ All slices merged to: {combined_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce673c-42c0-433a-882c-5f66f3a59a8a",
   "metadata": {},
   "source": [
    "### get_sliced_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225dbdf-fddf-4feb-a8eb-90edb3408703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sahi.predict import get_sliced_prediction\n",
    "from sahi.utils.cv import read_image\n",
    "from ultralytics import YOLO\n",
    "from osgeo import gdal\n",
    "import cv2\n",
    "\n",
    "def pixel2coord(x, y, geotransform):\n",
    "    xoff, a, b, yoff, d, e = geotransform\n",
    "    xp = a * x + b * y + a * 0.5 + b * 0.5 + xoff\n",
    "    yp = d * x + e * y + d * 0.5 + e * 0.5 + yoff\n",
    "    return xp, yp\n",
    "\n",
    "def sahi_pipeline_full_then_slicewise_save(\n",
    "    tif_path,\n",
    "    model_path,\n",
    "    output_dir,\n",
    "    slice_height=512,\n",
    "    slice_width=512,\n",
    "    overlap_height_ratio=0.2,\n",
    "    overlap_width_ratio=0.2,\n",
    "    confidence_threshold=0.3\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_csv_dir = os.path.join(output_dir, \"csv\")\n",
    "    output_img_dir = os.path.join(output_dir, \"slices\")\n",
    "    os.makedirs(output_csv_dir, exist_ok=True)\n",
    "    os.makedirs(output_img_dir, exist_ok=True)\n",
    "\n",
    "    image = read_image(tif_path)\n",
    "    pil_image = Image.open(tif_path)\n",
    "    raster = gdal.Open(tif_path)\n",
    "    geotransform = raster.GetGeoTransform()\n",
    "\n",
    "    model = model_path\n",
    "\n",
    "    result = get_sliced_prediction(\n",
    "        image=image,\n",
    "        detection_model=model,\n",
    "        slice_height=slice_height,\n",
    "        slice_width=slice_width,\n",
    "        overlap_height_ratio=overlap_height_ratio,\n",
    "        overlap_width_ratio=overlap_width_ratio,\n",
    "    )\n",
    "\n",
    "    image_width, image_height = pil_image.size\n",
    "    stride_h = int(slice_height * (1 - overlap_height_ratio))\n",
    "    stride_w = int(slice_width * (1 - overlap_width_ratio))\n",
    "\n",
    "    slice_record_dict = {}\n",
    "    for pred in result.object_prediction_list:\n",
    "        bbox = pred.bbox\n",
    "        xmin, ymin, xmax, ymax = bbox.minx, bbox.miny, bbox.maxx, bbox.maxy\n",
    "        conf = pred.score.value\n",
    "        center_x = (xmin + xmax) / 2\n",
    "        center_y = (ymin + ymax) / 2\n",
    "        geo_x, geo_y = pixel2coord(center_x, center_y, geotransform)\n",
    "\n",
    "        slice_row = int(center_y // stride_h)\n",
    "        slice_col = int(center_x // stride_w)\n",
    "        slice_index = slice_row * (image_width // stride_w + 1) + slice_col\n",
    "\n",
    "        if slice_index not in slice_record_dict:\n",
    "            slice_record_dict[slice_index] = []\n",
    "\n",
    "        slice_record_dict[slice_index].append({\n",
    "            'xmin': xmin, 'ymin': ymin, 'xmax': xmax, 'ymax': ymax,\n",
    "            'center_x': center_x, 'center_y': center_y,\n",
    "            'confidence': conf,\n",
    "            'geo_x': geo_x, 'geo_y': geo_y,\n",
    "            'slice_index': slice_index\n",
    "        })\n",
    "\n",
    "    for slice_index, record_list in slice_record_dict.items():\n",
    "        df = pd.DataFrame(record_list)\n",
    "        csv_name = os.path.join(output_csv_dir, f\"slice_{slice_index}.csv\")\n",
    "        df.to_csv(csv_name, index=False)\n",
    "\n",
    "        top = (slice_index // (image_width // stride_w + 1)) * stride_h\n",
    "        left = (slice_index % (image_width // stride_w + 1)) * stride_w\n",
    "        bottom = min(top + slice_height, image_height)\n",
    "        right = min(left + slice_width, image_width)\n",
    "        slice_box = (left, top, right, bottom)\n",
    "        slice_img = pil_image.crop(slice_box)\n",
    "        vis_img = np.array(slice_img)[:, :, ::-1].copy()\n",
    "\n",
    "        for row in record_list:\n",
    "            x1, y1 = int(row[\"xmin\"] - left), int(row[\"ymin\"] - top)\n",
    "            x2, y2 = int(row[\"xmax\"] - left), int(row[\"ymax\"] - top)\n",
    "            cv2.rectangle(vis_img, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "        slice_img_path = os.path.join(output_img_dir, f\"slice_{slice_index}.png\")\n",
    "        cv2.imwrite(slice_img_path, vis_img)\n",
    "\n",
    "        print(f\"[✓] Saved: slice_{slice_index}.csv and .png\")\n",
    "\n",
    "    return output_csv_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decda400-6a2e-4b39-8337-16f013fcf64e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sahi_pipeline_full_then_slicewise_save(\n",
    "    tif_path=\"/home/dhfmd/Dinglun/0529_small_RGB_V2_V3.tif\",\n",
    "    model_path=detection_model,\n",
    "    output_dir=\"my_sahi_results\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1383e-0896-4cb9-9207-856b254b8ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "pixel_dir = \"/home/dhfmd/Dinglun/my_sahi_results/csv\"\n",
    "combined_csv = \"/home/dhfmd/Dinglun/my_sahi_results/final_combined_geo_pixel.csv\"\n",
    "\n",
    "all_slice_csvs = glob.glob(os.path.join(pixel_dir, \"slice_*.csv\"))\n",
    "\n",
    "df_all = []\n",
    "for csv_file in all_slice_csvs:\n",
    "    if os.path.getsize(csv_file) == 0:\n",
    "        continue\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df[\"slice_name\"] = os.path.basename(csv_file).replace(\".csv\", \"\")\n",
    "        df_all.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error reading {csv_file}: {e}\")\n",
    "\n",
    "# Merge and save\n",
    "combined_df = pd.concat(df_all, ignore_index=True)\n",
    "combined_df.to_csv(combined_csv, index=False)\n",
    "print(f\"✅ All slices merged to: {combined_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f76c4-7084-4b1a-8d13-e732bb5a7ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
